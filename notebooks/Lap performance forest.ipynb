{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab5a08cd-0e26-4816-a0f9-74e1d4c919d6",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Set up secrets scope"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Set up the necessary variables\n",
    "databricks_instance = \"\"  # Replace with your actual Databricks instance URL\n",
    "token = \"\"  # Ensure this is your actual token \n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {token}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Create the secret scope with initial_manage_principal set to \"users\"\n",
    "scope_name = \"f1Scope\"\n",
    "create_scope_url = f\"{databricks_instance}/api/2.0/secrets/scopes/create\"\n",
    "data = {\n",
    "    \"scope\": scope_name,\n",
    "    \"initial_manage_principal\": \"users\"\n",
    "}\n",
    "\n",
    "response = requests.post(create_scope_url, headers=headers, data=json.dumps(data))\n",
    "\n",
    "# Check for errors and print the response\n",
    "if response.status_code == 200:\n",
    "    print(\"Secret scope created successfully.\")\n",
    "else:\n",
    "    print(f\"Failed to create secret scope: {response.status_code}\")\n",
    "    print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "9d2d3807-da7b-4bb8-84b3-cdb2be4984f0",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Check scope"
    }
   },
   "outputs": [],
   "source": [
    "# List all secret scopes\n",
    "display(dbutils.secrets.listScopes())\n",
    "\n",
    "# List all secrets in the specific scope\n",
    "display(dbutils.secrets.list(\"f1Scope\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa7e0b93-d9db-4b4b-967b-c333d93eea19",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Mount storage"
    }
   },
   "outputs": [],
   "source": [
    "storage_account_name = \"\"\n",
    "storage_account_key = dbutils.secrets.get(scope=\"f1Scope\", key=\"f1-key\")\n",
    "\n",
    "wasbs_source = f\"\"\n",
    "\n",
    "configs = {\n",
    "    f\"fs.azure.account.key.{storage_account_name}.blob.core.windows.net\": storage_account_key\n",
    "}\n",
    "\n",
    "dbutils.fs.mount(\n",
    "    source=wasbs_source,\n",
    "    mount_point=\"/mnt/raw-data\",\n",
    "    extra_configs=configs\n",
    ")\n",
    "\n",
    "display(dbutils.fs.mounts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77831367-cc5b-414e-ad74-596a8adb7e17",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Read data from storage"
    }
   },
   "outputs": [],
   "source": [
    "# 1) Define your storage account\n",
    "storage_account_name = \"\"\n",
    "\n",
    "# 2) Pull the real key from Key Vault\n",
    "storage_account_key = dbutils.secrets.get(\n",
    "    scope = \"f1Scope\",    # exactly your scope name\n",
    "    key   = \"f1-Key\"       # exactly your secret name\n",
    ")\n",
    "\n",
    "# 3) Base64 key\n",
    "spark.conf.set(\n",
    "    f\"fs.azure.account.key.{storage_account_name}.blob.core.windows.net\",\n",
    "    storage_account_key\n",
    ")\n",
    "\n",
    "# 2) Build WASBS URI\n",
    "wasbs_path = \"\"\n",
    "\n",
    "# 3) Read it\n",
    "lap_times_df = (\n",
    "    spark.read\n",
    "         .format(\"csv\")\n",
    "         .option(\"header\", \"true\")\n",
    "         .option(\"inferSchema\", \"true\")\n",
    "         .load(wasbs_path+\"/lap_times.csv\")\n",
    ")\n",
    "\n",
    "drivers_df = (\n",
    "    spark.read\n",
    "        .format(\"csv\")\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"inferSchema\", \"true\")\n",
    "        .load(wasbs_path+\"/drivers.csv\")\n",
    ")\n",
    "\n",
    "races_df = (\n",
    "    spark.read\n",
    "        .format(\"csv\")\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"inferSchema\", \"true\")\n",
    "        .load(wasbs_path+\"/races.csv\")\n",
    ")\n",
    "\n",
    "circuits_df = (\n",
    "    spark.read\n",
    "        .format(\"csv\")\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"inferSchema\", \"true\")\n",
    "        .load(wasbs_path+\"/circuits.csv\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f48d7d3-2060-4a99-bf0a-ba19948277a2",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Prepare table"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "#Join races to get year and circuitId\n",
    "lap_race_df = lap_times_df.join(races_df.select(\"raceId\", \"circuitId\", \"year\"),\n",
    "                              on=\"raceId\", how=\"inner\", )\n",
    "\n",
    "lap_race_df = lap_race_df.filter(lap_race_df[\"year\"] == 2024)\n",
    "lap_race_df = lap_race_df.join(circuits_df.select(\"circuitId\", \"circuitRef\",\"location\", \"name\", \"country\"),\n",
    "                               on=\"circuitId\", how=\"inner\")\n",
    "\n",
    "overview_table = lap_race_df.join(drivers_df.select(\"driverId\", \"driverRef\"),\n",
    "                                  on=\"driverId\", how=\"inner\")\n",
    "\n",
    "overview_table = overview_table.drop(\"milliseconds\")\n",
    "\n",
    "overview_table = overview_table.withColumn(\n",
    "    \"lap_sec\", (F.split(\"time\", \":\")[0].cast(\"int\") * 60 + F.split(\"time\", \":\")[1].cast(\"int\")))\n",
    "overview_table = overview_table.drop(\"time\")\n",
    "overview_table.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "161a1d42-8494-4dba-95ff-8c543f63e894",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Table EDA"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "overview_table.describe([\"lap_sec\"]).show()\n",
    "\n",
    "probs = [0.01, 0.25, 0.5, 0.75, 0.90, 0.99]\n",
    "\n",
    "# 3) Call approxQuantile with a small relative error (e.g. 0.001 for high accuracy)\n",
    "quantiles = overview_table.approxQuantile(\n",
    "    \"lap_sec\",   # column\n",
    "    probs,       # list of probabilities\n",
    "    0.001        # relativeError: 0.001 = very accurate\n",
    ")\n",
    "\n",
    "for p, q in zip(probs, quantiles):\n",
    "    print(f\"{int(p*100)}th percentile = {q:.3f} seconds\")\n",
    "\n",
    "min_bound, max_bound = 60.0, 200.0\n",
    "\n",
    "overview_table = overview_table.filter((F.col(\"lap_sec\") >= min_bound) & (F.col(\"lap_sec\") <= max_bound))\n",
    "\n",
    "overview_table.describe([\"lap_sec\"]).show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c29b2def-55a1-4672-a677-49afb5889a70",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Index & Vec Assembly"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "\n",
    "circuit_stats = overview_table.groupBy(\"circuitId\").agg(F.avg(\"lap_sec\").alias(\"circuit_mean\"))\n",
    "\n",
    "norm_df = (\n",
    "    overview_table\n",
    "        .join(circuit_stats, on=\"circuitId\", how=\"left\")\n",
    "        .withColumn(\"lap_diff\", F.col(\"lap_sec\") - F.col(\"circuit_mean\"))\n",
    "        .drop(\"lap_sec\")\n",
    ")\n",
    "\n",
    "drv_indexer = StringIndexer(inputCol=\"driverId\", outputCol=\"drv_idx\")\n",
    "cir_indexer = StringIndexer(inputCol=\"circuitId\", outputCol=\"cir_idx\")\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"drv_idx\", \"cir_idx\", \"lap\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "prep_pipeline = Pipeline(stages=[drv_indexer, cir_indexer, assembler])\n",
    "prepared_df = prep_pipeline.fit(norm_df).transform(norm_df)\n",
    "\n",
    "prepared_df.select(\n",
    "    \"driverRef\", \"circuitRef\", \"lap\", \"features\", \"lap_diff\"\n",
    ").show(5, truncate=False)\n",
    "\n",
    "train_df, test_df = prepared_df.randomSplit([0.8, 0.2], seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53b30fa9-ec3a-4739-9f19-a8fd99c7c260",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Random Forest Reg"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    labelCol=\"lap_diff\",\n",
    "    featuresCol=\"features\",\n",
    "    numTrees=50,\n",
    "    maxDepth=5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ac8c54d-7256-487a-bcaa-0a08f5d436c4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Model pipeline"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "model_pipeline = Pipeline(stages=[\n",
    "    drv_indexer,    \n",
    "    cir_indexer,\n",
    "    assembler,\n",
    "    rf\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "392cde5a-bf76-4409-a0fd-d1852e64b794",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Train model"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE = 8.616095730284968\n"
     ]
    }
   ],
   "source": [
    "# 1) Split the *prepared* data\n",
    "train_prep, test_prep = prepared_df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# 2) Just fit the RandomForestRegressor directly\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "rf = RandomForestRegressor(labelCol=\"lap_diff\", featuresCol=\"features\", numTrees=50, maxDepth=5)\n",
    "rf_model = rf.fit(train_prep)\n",
    "\n",
    "# 3) Predict and evaluate\n",
    "preds = rf_model.transform(test_prep)\n",
    "evaluator = RegressionEvaluator(labelCol=\"lap_diff\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "print(\"Test RMSE =\", evaluator.evaluate(preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5feb151-f8ef-4e4e-8bba-a04cd3a4e63b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Eval model performance"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 8.616 seconds\n",
      "R2: 0.216\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "evaluator_rmse = RegressionEvaluator(\n",
    "    labelCol=\"lap_diff\", \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName=\"rmse\"\n",
    ")\n",
    "\n",
    "evaluator_r2 = RegressionEvaluator(\n",
    "    labelCol=\"lap_diff\", \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName=\"r2\"\n",
    ")\n",
    "\n",
    "rmse = evaluator_rmse.evaluate(preds)\n",
    "r2 = evaluator_r2.evaluate(preds)\n",
    "\n",
    "print(f\"RMSE: {rmse:.3f} seconds\")\n",
    "print(f\"R2: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38db3f3a-d472-4398-8339-feced99ee18d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Feature Importance"
    }
   },
   "outputs": [],
   "source": [
    "importances = rf_model.featureImportances.toArray()\n",
    "\n",
    "for name, imp in zip([\"driver\",\"circuit\",\"lap_number\"], importances):\n",
    "    print(f\"{name:12s}: {imp:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Lap performance forest",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
